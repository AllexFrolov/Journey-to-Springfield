{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Project description\n",
    "\n",
    "В данном задании вам предстоит осуществить путешевствие в мир Спрингфилда,\n",
    "где вы сможете познакомиться со всеми любимыми персонажами Симпсонов.\n",
    "\n",
    "Основным заданием будет обучить классификатор на основе сверточных сетей,\n",
    "чтобы научиться отличать всех жителей Спрингфилда.\n",
    "# Dataset description\n",
    "Обучающая и тестовая выборка состоят из отрывков из мультсериала Симпсоны.\n",
    "Каждая картинка представлена в формате jpg c необходимой меткой - названием\n",
    "персонажа изображенного на ней. Тест был поделен на приватную и публичную\n",
    "часть в соотношении 95/5\n",
    "\n",
    "В тренировочном датасете примерно по 1000 картинок на каждый класс,\n",
    "но они отличаются размером.\n",
    "\n",
    "Метки классов представлены в виде названий папок, в которых лежат картинки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Table of content:\n",
    "1. [__Data preparation__](#data_preparation)\n",
    "2. [__Training models__](#training_models)\n",
    "    * [__Data augmentation__](#data_augmentation)\n",
    "    * [__Models__](#models)\n",
    "        * [_AlexNet_](#alexnet)\n",
    "        * [_VGG19_](#vgg19_bn)\n",
    "        * [_ResNet152_](#resnet152)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <a name='data_preparation'>1. Data preparation</a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data from here\n",
    "# https://www.kaggle.com/c/journey-springfield/data\n",
    "import os.path\n",
    "import sys\n",
    "if 'google' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    !mkdir Data\n",
    "    if not os.path.exists('Data/train'):\n",
    "        !cp drive/My\\ Drive/Colab/Stepik/Kaggle/journey-springfield.zip Data\n",
    "        !unzip -q -n Data/journey-springfield.zip -d Data\n",
    "        !rm Data/journey-springfield.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load model and train functions\n",
    "# from my other repositories\n",
    "# https://github.com/AllexFrolov/MobileNet_v3-PyTorch\n",
    "if not os.path.isfile('MobileNet_v3.py'):\n",
    "    !wget -q https://raw.githubusercontent.com/AllexFrolov/MobileNet_v3-PyTorch/master/MobileNet_v3.py\n",
    "if not os.path.isfile('functions.py'):\n",
    "    !wget -q https://raw.githubusercontent.com/AllexFrolov/MobileNet_v3-PyTorch/master/functions.py\n",
    "\n",
    "# -------- for debugging ----------\n",
    "import functions\n",
    "import MobileNet_v3\n",
    "from importlib import reload\n",
    "functions = reload(functions)\n",
    "MobileNet_v3 = reload(MobileNet_v3)\n",
    "# --------------------------------\n",
    "from functions import train, accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.model_selection import train_test_split\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = ImageFolder('Data/train/simpsons_dataset')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# look at the image\n",
    "np.random.seed(42)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(8, 8),\n",
    "                       sharey=True, sharex=True)\n",
    "\n",
    "for fig_x in ax.flatten():\n",
    "    random_characters = np.random.choice(len(dataset), 1)[0]\n",
    "    im, label = dataset[random_characters]\n",
    "    img_label = \" \".join(map(lambda x: x.capitalize(),\n",
    "                             dataset.classes[label].split('_')))\n",
    "    im = im.resize((224, 244))\n",
    "    fig_x.imshow(im)\n",
    "    if img_label is not None:\n",
    "        fig_x.set_title(img_label)\n",
    "    fig_x.grid(False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create custom DataLoader\n",
    "class MyDataLoader:\n",
    "    def __init__(self, data, indices: list, batch_size: int, transformer=None, shuffle=False):\n",
    "        assert type(shuffle) is bool, \\\n",
    "            f'shuffle should be bool type, not {type(shuffle)}'\n",
    "        assert type(batch_size) is int, \\\n",
    "            f'batch_size should be type int, not {type(batch_size)}'\n",
    "\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = indices\n",
    "        self.data = data\n",
    "        self.data_len = len(indices)\n",
    "        self.len_ = int(np.ceil(self.data_len / batch_size))\n",
    "\n",
    "        self.transformer = transformer\n",
    "        if transformer is None:\n",
    "            self.transformer = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        start_index = index * self.batch_size\n",
    "        end_index = min(self.data_len, start_index + self.batch_size)\n",
    "        batch_indices = self.indices[start_index: end_index]\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        for batch_index in batch_indices:\n",
    "            X, y = self.data[batch_index]\n",
    "            X = self.transformer(X)\n",
    "            X_batch.append(X)\n",
    "            y_batch.append(y)\n",
    "        if len(X_batch) > 1:\n",
    "            X_batch = torch.stack(X_batch)\n",
    "        else:\n",
    "            X_batch = torch.unsqueeze(X_batch[0], 0)\n",
    "        return X_batch, torch.Tensor(y_batch)\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "        for n_batch in range(self.len_):\n",
    "            return self.__getitem__(n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# split data\n",
    "train_val_indices, test_indices = train_test_split(np.arange(len(dataset)),\n",
    "                                                   train_size=0.75)\n",
    "\n",
    "train_indices, val_indices = train_test_split(train_val_indices,\n",
    "                                              train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# <a name='training_models'>2. Training models</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <a name='data_augmentation'>Data augmentation</a>\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "IM_SIZE = (224, 224)\n",
    "batch_size = 64\n",
    "\n",
    "train_transformer = transforms.Compose([transforms.Resize(IM_SIZE),\n",
    "                                        transforms.RandomRotation(15),\n",
    "                                        transforms.ColorJitter(0.5, 0.5),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                             [0.229, 0.224, 0.225])\n",
    "                                        ])\n",
    "\n",
    "val_transformer = transforms.Compose([transforms.Resize(IM_SIZE),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                             [0.229, 0.224, 0.225])\n",
    "                                        ])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = MyDataLoader(dataset, train_indices, batch_size,\n",
    "                            train_transformer, True)\n",
    "val_loader = MyDataLoader(dataset, val_indices, batch_size, val_transformer)\n",
    "test_loader = MyDataLoader(dataset, test_indices, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_classes = len(dataset.classes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <a name='models'>Models</a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models_history = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <a name='alexnet'>AlexNet</a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Download pretrained model\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "\n",
    "# freeze parameters\n",
    "for param in alexnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# replace last layer\n",
    "in_dim = alexnet.classifier[-1].in_features\n",
    "classifier = nn.Linear(in_dim, num_classes)\n",
    "alexnet.classifier[-1] = classifier\n",
    "alexnet = alexnet.to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "WEIGHT_DECAY = 1e-5\n",
    "optimizer = torch.optim.Adam(alexnet.parameters(),\n",
    "                             lr=lr,\n",
    "                             weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "FACTOR = 0.5\n",
    "THRESHOLD = 0.01\n",
    "PATIENCE = 1\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss().to(DEVICE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, 'max', FACTOR, PATIENCE, True, THRESHOLD\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "epoch_count=10\n",
    "history, best_param = \\\n",
    "        train(alexnet, train_loader, loss_func, optimizer, epoch_count,\n",
    "              accuracy, val_loader, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_history['alexnet'] = history"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <a name='vgg19_bn'>VGG19</a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Download pretrained model\n",
    "vgg19_bn = models.vgg19_bn(pretrained=True)\n",
    "\n",
    "# freeze parameters\n",
    "for param in vgg19_bn.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# replace last layer\n",
    "in_dim = vgg19_bn.classifier[-1].in_features\n",
    "classifier = nn.Linear(in_dim, num_classes)\n",
    "vgg19_bn.classifier[-1] = classifier\n",
    "vgg19_bn = vgg19_bn.to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "WEIGHT_DECAY = 1e-5\n",
    "optimizer = torch.optim.Adam(vgg19_bn.parameters(),\n",
    "                             lr=lr,\n",
    "                             weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "FACTOR = 0.5\n",
    "THRESHOLD = 0.01\n",
    "PATIENCE = 1\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss().to(DEVICE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, 'max', FACTOR, PATIENCE, True, THRESHOLD\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "epoch_count=10\n",
    "history, best_param = \\\n",
    "        train(vgg19_bn, train_loader, loss_func, optimizer, epoch_count,\n",
    "              accuracy, val_loader, scheduler)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models_history['vgg19_bn'] = history\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}